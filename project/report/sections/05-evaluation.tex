\section{Evaluation}
\label{sec:eval}

\subsection{Usability}

Informally, the usability argument for \bpfcontain{} is obvious. By exposing a high-level policy language to end-users with familiar semantics, \bpfcontain{}
\todo{The basic policy language is fairly high-level, focusing on the user's understanding of container behaviour rather than underlying operating system semantics. For instance, graphics, video, sound, and pts rules abstract away the underlying details of granting specific access to devices on the system.} For use cases that focus on limiting specific behaviours in a confined application, the default-allow policy option provides a convenient way to write ad-hoc policy without needing to worry about the underlying details. For instance, the default allow policy for restricting Discord's procfs scanning behaviour (c.f.~\Cref{lst:discord_b} in \Cref{sub:case_studies}) is only nine lines long, and consists of three actual policy rules.

To properly evaluate \bpfcontain{}'s usability, we must establish a strong basis for comparing it to other policy mechanisms, container-focused and otherwise. To that end, I propose conducting a user study, wherein different stakeholders are requested to evaluate \bpfcontain{} based on its perceived security level, ease of policy authorship, and alignment with user expectations. \todo{During this evaluation, a participant would be expected to use \bpfcontain{} to confine some commonly-used applications, such as text editors,} In particular, we might consider participant agreement with the following statements, evaluated on a Likert scale:
\begin{enumerate}[label=\bf Q\arabic*.]
  \item I was able to write the policy I needed for my use case.
  \item I was confident that my confined applications were more secure.
  \item \todo{Figure out more questions}
\end{enumerate}
To establish a basis for comparison with other policy mechanisms, participants would be asked to provide the same evaluation for an existing policy mechanism, such as AppArmor.

\subsection{Security}

\todo{Reason more about the security properties of the reference monitor}

Since \bpfcontain{} is implemented as an eBPF-based Linux security module, the totality of its mediation reduces to that of the Linux Security Module framework itself. \todo{But we also have additional mediation, such as the kprobe for kernel privilege escalation}

Evaluation of \bpfcontain{}'s security in practice will require demonstration that a correctly configured \bpfcontain{} policy can defend against container exploitation. This will involve three phases: (1) identifying relevant exploits for a set of container images; (2) constructing a security policy for these images; (3) testing that the security policy effectively prevents the exploits without affecting the desired functionality of the container image. Xin \etal~\cite{xin2018_container_security} presented a rigorous dataset of container exploits up to the year 2018, which can be used to bootstrap the testing dataset for \bpfcontain{} and will also serve as a strong basis for comparison against existing container security measures. This dataset will then be augmented with additional CVEs from 2019 and 2020.

In addition to container-specific exploits, we can also test \bpfcontain{}'s efficacy for ad-hoc confinement by constructing relevant \bpfcontain{} policy for commodity applications and testing against known CVEs or a set of undesired behaviour for these applications. For instance, these tests might involve verifying prevention of a code execution exploit in a web server or stopping Discord's unwanted procfs scanning behaviour using the policy depicted in \Cref{sub:case_studies}.

\subsection{Performance}

\bpfcontain{}'s performance will be evaluated using a variety of Linux benchmarking tests.

\todo{Describe the benchmarking tests we will use}
